name: Weekly Prospect Scrape

on:
  # Run every Monday at 8 AM UTC
  schedule:
    - cron: "0 8 * * 1"

  # Allow manual triggering
  workflow_dispatch:

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

jobs:
  weekly-scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install dependencies
        run: make install

      - name: Run weekly scrape
        run: |
          make production

      - name: Generate summary
        run: |
          echo "## Weekly Scrape Summary" > summary.md
          echo "Date: $(date)" >> summary.md
          echo "" >> summary.md
          echo "### Files Generated:" >> summary.md
          find exports/ -name "*.csv" -type f | wc -l | xargs echo "- CSV files:" >> summary.md
          find data/ -name "*.csv" -type f | wc -l | xargs echo "- Data files:" >> summary.md
          echo "" >> summary.md
          echo "### File Sizes:" >> summary.md
          find exports/ data/ -name "*.csv" -type f -exec ls -lh {} \; | head -10 >> summary.md

      - name: Upload weekly results
        uses: actions/upload-artifact@v4
        with:
          name: weekly-scrape-$(date +%Y%m%d)
          path: |
            exports/
            data/
            summary.md
          retention-days: 60
